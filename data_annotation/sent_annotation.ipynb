{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7ff932",
   "metadata": {},
   "source": [
    "# Annotating CSV files with sentiment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3500ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eff2d6",
   "metadata": {},
   "source": [
    "## Loading Seniment Dictionary - DK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c15a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sentiment dictionary\n",
    "with open('sentdict_pos_DK.txt', 'r') as f:\n",
    "    poslist = [el.split('\\t') for el in f.readlines()]\n",
    "    \n",
    "with open('sentdict_neg_DK.txt', 'r') as f:\n",
    "    neglist = [el.split('\\t') for el in f.readlines()]\n",
    "\n",
    "#aggregate sentiment words and their scores\n",
    "words = np.array([line[0]+'-'+line[1] for line in poslist] + \n",
    "                 [line[0]+'-'+line[1] for line in neglist])\n",
    "scores = np.array([float(line[2].rstrip()) for line in poslist] + \n",
    "                  [float(line[2].rstrip()) for line in neglist]) \n",
    "    \n",
    "#create series to function as dictionary -- allows for vectorized search\n",
    "sent_dict = dict(zip(words, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05905a15",
   "metadata": {},
   "source": [
    "## Loading Seniment Dictionary - BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858d4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sentiment dictionary\n",
    "with open('sentdict_pos_BG.txt', 'r') as f:\n",
    "    poslist = [el.split('\\t') for el in f.readlines()]\n",
    "    \n",
    "with open('sentdict_neg_BG.txt', 'r') as f:\n",
    "    neglist = [el.split('\\t') for el in f.readlines()]\n",
    "\n",
    "#aggregate sentiment words and their scores\n",
    "words = np.array([line[0]+'-'+line[1] for line in poslist] + \n",
    "                 [line[0]+'-'+line[1] for line in neglist])\n",
    "scores = np.array([float(line[2].rstrip()) for line in poslist] + \n",
    "                  [float(line[2].rstrip()) for line in neglist]) \n",
    "    \n",
    "#create series to function as dictionary -- allows for vectorized search\n",
    "sent_dictbg = dict(zip(words, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b327be",
   "metadata": {},
   "source": [
    "## Functions for reading and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d26981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_score(filename, lang, retur = False):\n",
    "    \"Reads .csv files and extracts lemmas with PoS tags, joining them into one string per word\"\n",
    "    \n",
    "    df = pd.read_csv(filename, dtype = object, delimiter = \"\\t\") #read file\n",
    "    \n",
    "    #extract lemmas\n",
    "    lemmas = (df['lemma'] + '-' + df['pos']).to_numpy()\n",
    "    \n",
    "    #score lemmas and add to dataframe\n",
    "    df['sentiment'] = score_doc(lemmas, lang)\n",
    "    \n",
    "    #save to csv\n",
    "    new_name = create_file(filename)\n",
    "    df.to_csv(new_name)\n",
    "    \n",
    "    if retur:#option for returning file during testing\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367a7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(filename):\n",
    "    \"Creates filepath for new file based on old one (input).\"\n",
    "    \n",
    "    root, name = os.path.split(filename)\n",
    "    root, year = os.path.split(root)\n",
    "    name, ext = os.path.splitext(name)\n",
    "    name = name + '.sent' + ext\n",
    "    newpath = os.path.join(newroot, year, name)\n",
    "        \n",
    "    return newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a3d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_doc(array, lang):\n",
    "    \"Scores each word in array according to sentiment dictionary, except between negations and punctuation.\"\n",
    "    \n",
    "    if lang == \"dk\":\n",
    "        res = np.array([sent_dict.get(lemma, np.nan) for lemma in array])\n",
    "    elif lang == \"bg\":\n",
    "        res = np.array([sent_dictbg.get(lemma, np.nan) for lemma in array])\n",
    "    neg_intervals = create_intervals(array, lang)\n",
    "    if len(neg_intervals) > 0:\n",
    "        res[neg_intervals] = np.nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c69a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intervals(array, lang):\n",
    "    \"Creates intervals between negations and punctuation for neutralizing sentiment\"\n",
    "    \n",
    "    if lang == 'dk':\n",
    "        negs = [\"ikke\", \"hverken\", \"ingen\", \"aldrig\"]\n",
    "    if lang == 'bg':\n",
    "        negs = [\"не\", \"нито\", \"никой\", \"никога\"] \n",
    "    \n",
    "    wordlist = [line.split(\"-\")[0] for line in array]\n",
    "    taglist = [line.split(\"-\")[1] for line in array]\n",
    "    \n",
    "    negword_indices = np.where([lemma in negs for lemma in wordlist])[0]\n",
    "    punct_indices = np.where([tag == 'PUNCT' for tag in taglist])[0]\n",
    "    intervals = []\n",
    "    \n",
    "    for i in negword_indices:\n",
    "        for j in punct_indices:\n",
    "            if j > i:\n",
    "                intervals += [i for i in range(i, j)]\n",
    "                break\n",
    "    return np.array(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef17d18",
   "metadata": {},
   "source": [
    "## Creating tagged corpus - DK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed94a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directory for tagged files\n",
    "newroot= \"ParlaMint-DK.TEI.CSV.SENT\"\n",
    "if not os.path.exists(newroot):\n",
    "    os.makedirs(newroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545cd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create subdirectories by year for tagged files\n",
    "for root, dirs, files in os.walk(\"ParlaMint-DK.TEI.CSV\", topdown=False):\n",
    "    for name in dirs:\n",
    "        #creating new folder\n",
    "        if name.isnumeric():\n",
    "            folderpath = os.path.join(newroot, name)\n",
    "            if not os.path.exists(folderpath):\n",
    "                os.makedirs(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25cfb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 39/39 [00:15<00:00,  2.58it/s]\n",
      "100%|███████████████████████████████████████████| 79/79 [00:35<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 100/100 [00:51<00:00,  1.94it/s]\n",
      "100%|█████████████████████████████████████████| 112/112 [01:03<00:00,  1.76it/s]\n",
      "100%|█████████████████████████████████████████| 102/102 [00:49<00:00,  2.04it/s]\n",
      "100%|█████████████████████████████████████████| 137/137 [01:14<00:00,  1.84it/s]\n",
      "100%|█████████████████████████████████████████| 153/153 [01:13<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████| 109/109 [00:56<00:00,  1.94it/s]\n",
      "100%|█████████████████████████████████████████| 116/116 [01:08<00:00,  1.70it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 24966.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#looping over corpus\n",
    "for root, dirs, files in os.walk(\"ParlaMint-DK.TEI.CSV\", topdown=False):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith('ana.csv'):\n",
    "            name = os.path.join(root, name)\n",
    "            read_and_score(name, \"dk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4466b38",
   "metadata": {},
   "source": [
    "## Creating tagged corpus - BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec0b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directory for tagged files\n",
    "newroot= \"ParlaMint-BG.TEI.CSV.SENT\"\n",
    "if not os.path.exists(newroot):\n",
    "    os.makedirs(newroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc87187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create subdirectories by year for tagged files\n",
    "for root, dirs, files in os.walk(\"ParlaMint-BG.TEI.CSV\", topdown=False):\n",
    "    for name in dirs:\n",
    "        #creating new folder\n",
    "        if name.isnumeric():\n",
    "            folderpath = os.path.join(newroot, name)\n",
    "            if not os.path.exists(folderpath):\n",
    "                os.makedirs(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4041039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 27/27 [00:10<00:00,  2.68it/s]\n",
      "100%|███████████████████████████████████████████| 87/87 [00:38<00:00,  2.26it/s]\n",
      "100%|█████████████████████████████████████████| 132/132 [00:46<00:00,  2.85it/s]\n",
      "100%|█████████████████████████████████████████| 101/101 [00:28<00:00,  3.54it/s]\n",
      "100%|█████████████████████████████████████████| 122/122 [00:31<00:00,  3.90it/s]\n",
      "100%|███████████████████████████████████████████| 70/70 [00:24<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████| 122/122 [00:35<00:00,  3.47it/s]\n",
      "100%|█████████████████████████████████████████| 132/132 [00:40<00:00,  3.25it/s]\n",
      "100%|█████████████████████████████████████████| 128/128 [00:40<00:00,  3.17it/s]\n",
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 35848.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#looping over corpus\n",
    "for root, dirs, files in os.walk(\"ParlaMint-BG.TEI.CSV\", topdown=False):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith('ana.csv'):\n",
    "            name = os.path.join(root, name)\n",
    "            read_and_score(name, \"bg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43e5a2",
   "metadata": {},
   "source": [
    "# Aggregating data \n",
    "\n",
    "    # see Rheault et al. about representing the divergence in terms of deviation from the mean\n",
    "    # remember to divide by number of words when assessing sentiment score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a682ecc",
   "metadata": {},
   "source": [
    "## Scoring all speeches - DK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "879a36d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 39/39 [00:04<00:00,  8.83it/s]\n",
      "100%|█████████████████████████████████████████████| 79/79 [00:08<00:00,  8.78it/s]\n",
      "100%|███████████████████████████████████████████| 100/100 [00:13<00:00,  7.62it/s]\n",
      "100%|███████████████████████████████████████████| 112/112 [00:15<00:00,  7.21it/s]\n",
      "100%|███████████████████████████████████████████| 102/102 [00:12<00:00,  8.03it/s]\n",
      "100%|███████████████████████████████████████████| 137/137 [00:18<00:00,  7.50it/s]\n",
      "100%|███████████████████████████████████████████| 153/153 [00:17<00:00,  8.65it/s]\n",
      "100%|███████████████████████████████████████████| 109/109 [00:14<00:00,  7.54it/s]\n",
      "100%|███████████████████████████████████████████| 116/116 [00:17<00:00,  6.81it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.DataFrame({\"ID\": [], \"Sentiment\":[], \"Word_total\":[], \"Score\":[], \"Title\":[], \"Date\":[],  \"Body\":[],\n",
    "                       \"Term\":[],\"Session\":[], \"Meeting\":[], \"Sitting\":[],\"Agenda\":[], \"Subcorpus\": [], \n",
    "                       \"Speaker_role\": [],\"Speaker_MP\": [], \"Speaker_Minister\": [], \"Speaker_party\": [],  \n",
    "                       \"Speaker_party_name\": [], \"Party_status\":[], \"Speaker_name\":[], \"Speaker_gender\":[], \n",
    "                       \"Speaker_birth\":[], \"Topic_title\":[], \"Question\":[], \"Debate\":[]})\n",
    "big_df.to_csv(\"ParlaMint-DK-SENT.csv\")\n",
    "\n",
    "for root, dirs, files in os.walk(\"ParlaMint-DK.TEI.CSV.SENT\", topdown=False):\n",
    "    files = [name for name in files if name.endswith(\"ana.sent.csv\")]\n",
    "    for name in tqdm(files):\n",
    "        sentfile = os.path.join(root, name)\n",
    "        metaroot = \"ParlaMint-DK.txt\"\n",
    "        year = os.path.split(root)[1]\n",
    "        metafile = os.path.join(metaroot, year, name.rstrip(\"ana.sent.csv\") + \"-meta.csv\")\n",
    "    \n",
    "        df = pd.read_csv(sentfile, dtype = object, index_col = 0)\n",
    "        df = df[df[\"pos\"] != \"PUNCT\" ] #remove punctuation from word count\n",
    "        meta = pd.read_csv(metafile, delimiter = \"\\t\", index_col = 0)\n",
    "        joined = df.join(meta.set_index(\"ID\"), on = 'id' )\n",
    "        \n",
    "        totals = df.groupby('id')['lemma'].count().astype(float)\n",
    "        df['sentiment'] = df['sentiment'].astype(float)\n",
    "        sentiment = df.groupby('id')['sentiment'].sum()\n",
    "        speech_scores = sentiment/totals\n",
    "        \n",
    "        \n",
    "        #try weighting the negatives more \n",
    "        \n",
    "        new_frame = pd.DataFrame({\"Sentiment\":sentiment, \"Word_total\":totals, \n",
    "                                  \"Score\":speech_scores}).reset_index()\n",
    "        new_joined = new_frame.join(meta.set_index(\"ID\"), on = 'id')\n",
    "        new_joined.to_csv(\"ParlaMint-DK-SENT.csv\", mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a7990",
   "metadata": {},
   "source": [
    "## Add Information\n",
    "\n",
    "    #add Left-Right annotation?\n",
    "    #add Government name? E.g. ThorningII, RasmussenII, RasmussenIII, FrederiksenI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bb93ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dk = pd.read_csv(\"ParlaMint-DK-SENT.csv\", delimiter = \",\", dtype = object)\n",
    "df_dk[\"YearMonth\"] = df_dk[\"Date\"].str[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de27ce7",
   "metadata": {},
   "source": [
    "### Government info based on dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3c3982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(datelist):\n",
    "    d = datelist.split(\"-\")\n",
    "    return datetime.datetime(int(d[0]), int(d[1]), int(d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e082e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398610,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datearray = df_dk[\"Date\"].to_numpy(dtype= str)\n",
    "datearray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16d3c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "datearray = np.array([date(x) for x in datearray])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f9adad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates taken from file \n",
    "thstart, thend = datetime.datetime(2014, 2, 3), datetime.datetime(2015, 6, 27) #Thorning-Schmidt II government\n",
    "ra2start, ra2end = datetime.datetime(2015, 5, 28), datetime.datetime(2016, 11, 27) #Rasumssen II government\n",
    "ra3start, ra3end = datetime.datetime(2016, 11, 28), datetime.datetime(2019, 6, 5) #Rasmussen III government\n",
    "frstart, frend = datetime.datetime(2019, 6, 7), datetime.datetime(2022, 6, 7) #Frederiksen I government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04156c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index intervals\n",
    "thorning = np.where(np.logical_and(thstart <= datearray, datearray <= thend))\n",
    "rasmussenii = np.where(np.logical_and(ra2start <= datearray, datearray <= ra2end))\n",
    "rasmusseniii = np.where(np.logical_and(ra3start <= datearray, datearray <= ra3end))\n",
    "frederiksen = np.where(np.logical_and(frstart <= datearray, datearray <= frend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "104088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "government = np.empty((len(df_dk), 1), dtype = object) #create array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b40b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "government[thorning, 0] = \"Thorning-Schmidt II\"\n",
    "government[rasmussenii, 0] = \"Rasmussen II\"\n",
    "government[rasmusseniii, 0] = \"Rasmussen III\"\n",
    "government[frederiksen, 0] = \"Frederiksen I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "037fd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dk[\"Government\"] = government"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71c3f7",
   "metadata": {},
   "source": [
    "### Political Orientation (Left/Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c096a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [\"S\", \"RV\", \"SF\", \"EL\", \"ALT\"]\n",
    "right = [\"V\", \"KF\", \"LA\", \"DF\", \"NB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83e6b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "partyarray = df_dk[\"Speaker_party\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fe119bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloc = np.empty((len(df_dk), 1), dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76f0c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "lindex = df_dk[\"Speaker_party\"].isin(left)\n",
    "rindex = df_dk[\"Speaker_party\"].isin(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f648fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloc[lindex] = \"Left\"\n",
    "bloc[rindex] = \"Right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a2315b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dk[\"Bloc\"] = bloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155a4ce",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d49d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dk\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParlaMint-DK-SENT.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dk' is not defined"
     ]
    }
   ],
   "source": [
    "df_dk.to_csv(\"ParlaMint-DK-SENT.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73066683",
   "metadata": {},
   "source": [
    "## Scoring all speeches - BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a89fa026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 28/28 [00:10<00:00,  2.63it/s]\n",
      "100%|███████████████████████████████████████████| 88/88 [00:12<00:00,  7.25it/s]\n",
      "100%|█████████████████████████████████████████| 133/133 [00:14<00:00,  9.18it/s]\n",
      "100%|█████████████████████████████████████████| 102/102 [00:09<00:00, 10.51it/s]\n",
      "100%|█████████████████████████████████████████| 123/123 [00:10<00:00, 11.45it/s]\n",
      "100%|███████████████████████████████████████████| 71/71 [00:07<00:00,  9.44it/s]\n",
      "100%|█████████████████████████████████████████| 123/123 [00:11<00:00, 11.15it/s]\n",
      "100%|█████████████████████████████████████████| 133/133 [00:13<00:00, 10.13it/s]\n",
      "100%|█████████████████████████████████████████| 129/129 [00:13<00:00,  9.64it/s]\n",
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 29330.80it/s]\n"
     ]
    }
   ],
   "source": [
    "big_bg = pd.DataFrame({\"ID\": [], \"Sentiment\":[], \"Word_total\":[], \"Score\":[], \"Negscore\":[], \"Title\":[], \n",
    "                       \"Date\":[],  \"Body\":[],\n",
    "                       \"Term\":[],\"Session\":[], \"Meeting\":[], \"Sitting\":[],\"Agenda\":[], \"Subcorpus\": [], \n",
    "                       \"Speaker_role\": [],\"Speaker_MP\": [], \"Speaker_Minister\": [], \"Speaker_party\": [],  \n",
    "                       \"Speaker_party_name\": [], \"Party_status\":[], \"Speaker_name\":[], \"Speaker_gender\":[], \n",
    "                       \"Speaker_birth\":[], \"Topic_title\":[], \"Meeting_type\":[], \"Comission\": []})\n",
    "big_bg.to_csv(\"ParlaMint-BG-SENT.csv\")\n",
    "\n",
    "big_bg = pd.DataFrame({\"sent\":[], \"word_total\":[], \"score\":[]})\n",
    "\n",
    "for root, dirs, files in os.walk(\"ParlaMint-BG.TEI.CSV.SENT\", topdown=False):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith(\"ana.sent.csv\"):\n",
    "            sentfile = os.path.join(root, name)\n",
    "            metaroot = \"ParlaMint-BG.txt\"\n",
    "            year = os.path.split(root)[1]\n",
    "            metafile = os.path.join(metaroot, year, name.rstrip(\"ana.sent.csv\") + \"-meta.csv\")\n",
    "\n",
    "            df = pd.read_csv(sentfile, dtype = object, index_col = 0)\n",
    "            df = df[df[\"pos\"] != \"PUNCT\" ] #remove punctuation from word count\n",
    "            meta = pd.read_csv(metafile, delimiter = \"\\t\", index_col = 0)\n",
    "            joined = df.join(meta.set_index(\"ID\"), on = 'id' )\n",
    "\n",
    "            totals = df.groupby('id')['lemma'].count().astype(float)\n",
    "            df['sentiment'] = df['sentiment'].astype(float)\n",
    "            sentiment = df.groupby('id')['sentiment'].sum()\n",
    "            speech_scores = sentiment/totals\n",
    "            \n",
    "            #weighting negative words more\n",
    "            df[\"negscore\"] = df[\"sentiment\"] #copy\n",
    "            negative_mask = df[\"negscore\"] < 0\n",
    "            df.loc[negative_mask, \"negscore\"] = df.loc[negative_mask, \"negscore\"]*2\n",
    "            negscores = df.groupby(\"id\")[\"negscore\"].sum()\n",
    "\n",
    "            new_frame = pd.DataFrame({\"Sentiment\":sentiment, \"Word_total\":totals, \n",
    "                                      \"Score\":speech_scores, \"Negscore\":negscores}).reset_index()\n",
    "            new_joined = new_frame.join(meta.set_index(\"ID\"), on = 'id')\n",
    "            new_joined.to_csv(\"ParlaMint-BG-SENT.csv\", mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451999f",
   "metadata": {},
   "source": [
    "## Add information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91dd6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg = pd.read_csv(\"ParlaMint-BG-SENT.csv\", delimiter = \",\", dtype = object)\n",
    "df_bg[\"YearMonth\"] = df_bg[\"Date\"].str[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ead32",
   "metadata": {},
   "source": [
    "#### Correcting party annotation (cyrillic to latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5457c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_bg.loc[df_bg[\"Speaker_party\"] == 'ГЕРБ'].index\n",
    "df_bg.loc[rows, \"Speaker_party\"] = \"GERB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9314f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_bg.loc[df_bg[\"Speaker_party\"] == 'ДПС'].index\n",
    "df_bg.loc[rows, \"Speaker_party\"] = \"MRF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d151a8",
   "metadata": {},
   "source": [
    "### Government info based on dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1aec7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(datelist):\n",
    "    d = datelist.split(\"-\")\n",
    "    return datetime.datetime(int(d[0]), int(d[1]), int(d[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ace5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210017,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datearray = df_bg[\"Date\"].to_numpy(dtype= str)\n",
    "datearray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cef07aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datearray = np.array([date(x) for x in datearray])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05e51804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates taken from file \n",
    "blstart, blend = datetime.datetime(2014, 8, 11), datetime.datetime(2014, 11, 7) #Bliznashki\n",
    "bb2start, bb2end = datetime.datetime(2014, 11, 7), datetime.datetime(2017, 1, 27) #Borisov II\n",
    "gestart, geend = datetime.datetime(2017, 1, 27), datetime.datetime(2017, 5, 4) #Gerdzhikov\n",
    "bb3start, bb3end = datetime.datetime(2017, 5, 4), datetime.datetime(2021, 4, 15) #Borisov III\n",
    "ya1start, ya1end = datetime.datetime(2021, 5, 12), datetime.datetime(2021, 9, 16) #Yanev I\n",
    "ya2start, ya2end = datetime.datetime(2021, 9, 16), datetime.datetime(2021, 12, 13) #Yanev II\n",
    "pestart, peend = datetime.datetime(2021, 12, 13), datetime.datetime(2022, 8, 2) #Petkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23f3ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index intervals\n",
    "bliznashki = np.where(np.logical_and(blstart <= datearray, datearray < blend))\n",
    "borisov2 = np.where(np.logical_and(bb2start <= datearray, datearray < bb2end))\n",
    "gerdzhikov = np.where(np.logical_and(gestart <= datearray, datearray < geend))\n",
    "borisov3 = np.where(np.logical_and(bb3start <= datearray, datearray < bb3end))\n",
    "yanev1 = np.where(np.logical_and(ya1start <= datearray, datearray < ya1end))\n",
    "yanev2 = np.where(np.logical_and(ya2start <= datearray, datearray < ya2end))\n",
    "petkov = np.where(np.logical_and(pestart <= datearray, datearray < peend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "455bfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "government = np.empty((len(df_bg), 1), dtype = object) #create array\n",
    "caretaker = np.empty((len(df_bg), 1), dtype = object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d754768",
   "metadata": {},
   "outputs": [],
   "source": [
    "government[bliznashki, 0] = \"Bliznashki\"\n",
    "caretaker[bliznashki, 0] = True\n",
    "\n",
    "government[borisov2, 0] = \"Borisov II\"\n",
    "caretaker[borisov2, 0] = False\n",
    "\n",
    "government[gerdzhikov, 0] = \"Gerdzhikov\"\n",
    "caretaker[gerdzhikov, 0] = True\n",
    "\n",
    "government[borisov3, 0] = \"Borisov III\"\n",
    "caretaker[borisov3, 0] = False\n",
    "\n",
    "government[yanev1, 0] = \"Yanev I\"\n",
    "caretaker[yanev1, 0] = True\n",
    "\n",
    "government[yanev2, 0] = \"Yanev II\"\n",
    "caretaker[yanev2, 0] = True\n",
    "\n",
    "government[petkov, 0] = \"Petkov\"\n",
    "caretaker[petkov, 0] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82f5b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg[\"Government\"] = government\n",
    "df_bg[\"Caretaker\"] = caretaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad11f7",
   "metadata": {},
   "source": [
    "### Political Orientation (Left/Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39277def",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_bg.loc[df_bg[\"Speaker_party\"] == \"DB;WCC\"].index\n",
    "df_bg.loc[row, \"Speaker_party\"] = \"WCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9a0e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = [\"BSPLB\", \"ABV\", \"WCC\", \"BSPFB\", \"RUBGWC\", \"RUTO\", ]\n",
    "right = [\"RB\", \"PF\", \"BDC-NU\", \"AP\", \"GERB\", \"MRF\", \"TISP\", \"GERB-UDF\", \"RP\", \"DB\", \"UP\", \"VOLYA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "094de022",
   "metadata": {},
   "outputs": [],
   "source": [
    "partyarray = df_bg[\"Speaker_party\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f9c9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloc = np.empty((len(df_bg), 1), dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63c48b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lindex = df_bg[\"Speaker_party\"].isin(left)\n",
    "rindex = df_bg[\"Speaker_party\"].isin(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9562d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloc[lindex] = \"Left\"\n",
    "bloc[rindex] = \"Right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8972b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg[\"Bloc\"] = bloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b111a8",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b30635fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg.to_csv(\"ParlaMint-BG-SENT.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de301c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46f15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d38ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ee024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc25e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ece63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
